{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requires\n",
    "1. Sampling Rate : 16000 \n",
    "2. Channels : Mono\n",
    "3. Type : Wav\n",
    "4. Not more that 1 min (5 second to be safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.call('rm temp.wav',shell=True)\n",
    "#converting mp3 to wav\n",
    "subprocess.call('ffmpeg -i {} -acodec pcm_s16le -ar 16000 -ac 1 temp.wav'.format('dialog1.mp3'),shell=True)\n",
    "#removing previous present files\n",
    "subprocess.call('rm parts/*', shell=True)\n",
    "#segmenting our .wav in parts of 5 seconds for processing \n",
    "subprocess.call('ffmpeg -i temp.wav -f segment -segment_time 5 -c copy parts/out%09d.wav',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['out000000000.wav',\n",
       " 'out000000001.wav',\n",
       " 'out000000002.wav',\n",
       " 'out000000003.wav',\n",
       " 'out000000004.wav',\n",
       " 'out000000005.wav',\n",
       " 'out000000006.wav',\n",
       " 'out000000007.wav',\n",
       " 'out000000008.wav',\n",
       " 'out000000009.wav',\n",
       " 'out000000010.wav',\n",
       " 'out000000011.wav',\n",
       " 'out000000012.wav']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# API KEY : Issued in the Name of Aditya Jain : Please do not share\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"../Audio-to-speech-aa00874e061f.json\"\n",
    "files = os.listdir('parts')\n",
    "sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:24<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from tqdm import tqdm\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "conversation = list()\n",
    "\n",
    "for file in tqdm(sorted(files)):\n",
    "\n",
    "    with open('parts/'+file, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.types.RecognitionAudio(content=content)\n",
    "\n",
    "    config = speech.types.RecognitionConfig(\n",
    "        encoding=speech.enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code='en-US',\n",
    "        enable_speaker_diarization=True,\n",
    "        diarization_speaker_count=2)\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    # The transcript within each result is separate and sequential per result.\n",
    "    # However, the words list within an alternative includes all the words\n",
    "    # from all the results thus far. Thus, to get all the words with speaker\n",
    "    # tags, you only have to take the words list from the last result:\n",
    "    result = response.results[-1]\n",
    "\n",
    "    words_info = result.alternatives[0].words\n",
    "    current = words_info[0].speaker_tag\n",
    "    # Printing out the output:\n",
    "    ongoing = {words_info[0].speaker_tag:[]}\n",
    "    for word_info in words_info:\n",
    "        #print(\"word: '{}', speaker_tag: {}\".format(word_info.word,word_info.speaker_tag))\n",
    "        if word_info.speaker_tag != current:\n",
    "            conversation.append(ongoing)\n",
    "            ongoing = { word_info.speaker_tag :[] }\n",
    "            current = word_info.speaker_tag\n",
    "            ongoing[word_info.speaker_tag].append(word_info.word)\n",
    "        else:\n",
    "            ongoing[word_info.speaker_tag].append(word_info.word)\n",
    "    conversation.append(ongoing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 1 : hi I'm homeless what's your name\n",
      "Speaker 2 : my name is Ricky\n",
      "Speaker 1 : ECU new student here\n",
      "Speaker 2 : I have my first lesson this morning\n",
      "Speaker 1 : you and you student to\n",
      "Speaker 2 : know I've been here for six months\n",
      "Speaker 2 : a long time so long really\n",
      "Speaker 1 : 3 what about you I'm in Xbox one who's your teacher\n",
      "Speaker 1 : don't remember\n",
      "Speaker 2 : her name but she's got curly red hair\n",
      "Speaker 1 : yes I think so that's probably an Wallace\n",
      "Speaker 2 : do you know her is she your teacher to know but she told me last time\n",
      "Speaker 2 : have you been here only a week. Long would you live\n",
      "Speaker 2 : well I'm staying at the YMCA at the moment I'm looking for someone more permanent\n",
      "Speaker 1 : do you know of any good places\n",
      "Speaker 2 : actually my friend has a spare room\n",
      "Speaker 2 : are apartment and she's looking for a flatmate phone number\n",
      "Speaker 1 : thanks for your help can I buy you a coffee\n"
     ]
    }
   ],
   "source": [
    "for converse in conversation:\n",
    "    print( \"Speaker {} : {}\".format( list(converse.keys())[0], \" \".join(converse[list(converse.keys())[0]]) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages\n",
    "1. diarization available (seperating speakers)\n",
    "2. Very fast\n",
    "3. Easy to use, Great documentation\n",
    "\n",
    "### Disadvantages\n",
    "1. Difficult to process nouns like names, places etc\n",
    "2. Omits some part of speech sometimes, but most words are recognized.\n",
    "3. Paid on basis of monthly amount of characters processed\n",
    "4. Uses internet connection, since it is a API\n",
    "\n",
    "### Other Options\n",
    "1. PocketSphinx - works offline, lack of documentation, Mainly for Java\n",
    "2. IBM speech to text - online, paid, not good as google cloud speech to text\n",
    "3. Microsoft Bing Voice Recognition - online, paid, not good as google cloud speech to text\n",
    "4. Many more which are not famous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
